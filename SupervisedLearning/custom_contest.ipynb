{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "748394da8a867656525da93a356544f0f15fb0021d7a843e967cb2c6876245f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 종류\n",
      "(89355, 24)\n",
      "Index(['신고번호', '신고일자', '통관지세관부호', '신고인부호', '수입자부호', '해외거래처부호', '특송업체부호',\n",
      "       '수입통관계획코드', '수입신고구분코드', '수입거래구분코드', '수입종류코드', '징수형태코드', '신고중량(KG)',\n",
      "       '과세가격원화금액', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호', '적출국가코드', '원산지국가코드',\n",
      "       '관세율구분코드', '관세율', '검사결과코드', '우범여부', '핵심적발'],\n",
      "      dtype='object')\n",
      "Index(['신고일자', '통관지세관부호', '신고인부호', '해외거래처부호', '특송업체부호', '수입통관계획코드', '수입신고구분코드',\n",
      "       '수입거래구분코드', '수입종류코드', '징수형태코드', '운송수단유형코드', '반입보세구역부호', 'HS10단위부호',\n",
      "       '적출국가코드', '원산지국가코드', '관세율구분코드', '검사결과코드'],\n",
      "      dtype='object')\n",
      "<ipython-input-2-a903598d50b9>:27: RuntimeWarning: divide by zero encountered in log\n",
      "  train_price=np.log(train_origin_data.pop('과세가격원화금액').to_numpy()).reshape(-1,1)\n"
     ]
    }
   ],
   "source": [
    "train_origin_data=pd.read_csv('./data/custom_contest/train.csv')\n",
    "test_origin_data=pd.read_csv('./data/custom_contest/test.csv')\n",
    "'''\n",
    "0은 바꿀 필요가 있음 o는 숫자이므로 유지\n",
    "신고번호 = x\n",
    "신고일자 = x\n",
    "통관지세관부호 = o\n",
    "신고인부호 = 0\n",
    "수입자부호 = 0\n",
    "해외 거래처 부호 = 0\n",
    "특송업체부호 = 0 \n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 확인\n",
    "print('Data 종류')\n",
    "print(train_origin_data.shape)\n",
    "print(train_origin_data.columns)\n",
    "# 쓸모없는 데이터 날리기\n",
    "train_origin_data.drop('신고번호',axis=1,inplace=True)\n",
    "train_origin_data.drop('수입자부호',axis=1,inplace=True)\n",
    "# target 두개 분리\n",
    "crime_target=torch.tensor(train_origin_data.pop('우범여부').to_numpy())\n",
    "priority_target=torch.tensor(train_origin_data.pop('핵심적발').to_numpy())\n",
    "#numerical data 분리\n",
    "train_weight=np.log(train_origin_data.pop('신고중량(KG)').to_numpy()).reshape(-1,1)\n",
    "train_price=np.log(train_origin_data.pop('과세가격원화금액').to_numpy()).reshape(-1,1)\n",
    "train_custom_rate=train_origin_data.pop('관세율').to_numpy().reshape(-1,1)\n",
    "# 분리 확인\n",
    "print(train_origin_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "신고일자 : (89355, 325)\n",
      "통관지세관부호 : (89355, 40)\n",
      "신고인부호 : (89355, 965)\n",
      "해외거래처부호 : (89355, 4779)\n",
      "특송업체부호 : (89355, 81)\n",
      "수입통관계획코드 : (89355, 7)\n",
      "수입신고구분코드 : (89355, 4)\n",
      "수입거래구분코드 : (89355, 25)\n",
      "수입종류코드 : (89355, 10)\n",
      "징수형태코드 : (89355, 9)\n",
      "운송수단유형코드 : (89355, 6)\n",
      "반입보세구역부호 : (89355, 568)\n",
      "HS10단위부호 : (89355, 2419)\n",
      "적출국가코드 : (89355, 89)\n",
      "원산지국가코드 : (89355, 94)\n",
      "관세율구분코드 : (89355, 35)\n",
      "검사결과코드 : (89355, 429)\n"
     ]
    }
   ],
   "source": [
    "for key in train_origin_data.keys():\n",
    "    enc=OneHotEncoder().fit(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "    encoded_data=enc.transform(train_origin_data[key].to_numpy().reshape(-1,1))\n",
    "    print(key,':',encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "encoded dataset (89355, 9885)\n",
      "torch.Size([89355, 9888])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# One hot encoding\n",
    "enc=OneHotEncoder(dtype=np.float32).fit(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns)))\n",
    "train_encoded_data=enc.transform(train_origin_data.to_numpy().reshape(-1,len(train_origin_data.columns))).toarray()\n",
    "print(\"encoded dataset\",train_encoded_data.shape)\n",
    "\n",
    "# concat dataset\n",
    "train_price_tensor=torch.tensor(train_price,dtype=torch.float)\n",
    "train_weight_tensor=torch.tensor(train_weight,dtype=torch.float)\n",
    "train_custom_rate_tensor=torch.tensor(train_custom_rate,dtype=torch.float)\n",
    "train_encoded_data_tensor=torch.tensor(train_encoded_data,dtype=torch.float)\n",
    "train_tensor_data=torch.cat((train_encoded_data_tensor,train_price_tensor,train_weight_tensor,train_custom_rate_tensor),dim=1)\n",
    "del train_price,train_weight,train_custom_rate,train_encoded_data\n",
    "print(train_tensor_data.size())\n",
    "# shape 잘라야쥬\n",
    "# train,valid,test set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset=TensorDataset(train_tensor_data,crime_target)\n",
    "model=nn.Sequential(nn.Linear(train_tensor_data.shape[1],500),\\\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,2)\n",
    "    )\n",
    "batch_size=64\n",
    "train_data_loader=DataLoader(dataset,batch_size=batch_size,shuffle=True,)\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.000001,weight_decay=1e-4)\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1epoch 64/89355, Accurcay: 76.56 Loss:0.61746\n",
      "WARNING: non-finite loss\n",
      "1epoch 6464/89355, Accurcay: 77.07 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 12864/89355, Accurcay: 76.97 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 19264/89355, Accurcay: 77.07 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 25664/89355, Accurcay: 76.91 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 32064/89355, Accurcay: 76.85 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 38464/89355, Accurcay: 76.84 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 44864/89355, Accurcay: 76.94 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 51264/89355, Accurcay: 76.91 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 57664/89355, Accurcay: 76.91 Loss:nan\n",
      "WARNING: non-finite loss\n",
      "1epoch 64064/89355, Accurcay: 76.89 Loss:nan\n",
      "WARNING: non-finite loss\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c2e9d0635188>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "for epoch in range(1,epochs+1):\n",
    "    total=0\n",
    "    correct=0.0\n",
    "    train_loss=0.0\n",
    "    for batch_idx, (data,targets) in enumerate(train_data_loader):\n",
    "        data,targets=data.cuda(),targets.cuda()\n",
    "        outputs=model(data)\n",
    "        loss=criterion(outputs,targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if not torch.isfinite(loss):\n",
    "            if batch_idx%100==0:\n",
    "                print('WARNING: non-finite loss')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).sum().float().cpu()\n",
    "        train_loss+=loss.item()\n",
    "        if batch_idx%100==0:\n",
    "            print('{}epoch {}/{}, Accurcay: {:.2f} Loss:{:.5f}'.format(epoch,total,len(train_data_loader.dataset),correct/total*100.0,train_loss/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}